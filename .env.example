# Google OAuth Configuration
GOOGLE_CLIENT_ID=your_client_id_here
GOOGLE_CLIENT_SECRET=your_client_secret_here
GOOGLE_REDIRECT_URI=http://127.0.0.1:8000

# Classifier provider switch. Safe default keeps current behavior.
CLASSIFIER_PROVIDER=keyword  # options: keyword|python|llm

# Local LLM model config (Electron-only use; web build must not import it)
ONLYJOBS_MODEL_PATH=./models/model.gguf
ONLYJOBS_MODEL_URL=   # optional; if empty use default downloader URL we will add next step
ONLYJOBS_MODEL_NAME="Llama-3.2-3B Q4_K_M"

# Inference parameters (optimized for speed and reliability)
ONLYJOBS_TEMPERATURE=0.1
ONLYJOBS_MAX_TOKENS=96                       # reduced for faster generation (96 tokens sufficient for job classification JSON)
ONLYJOBS_CTX=768                            # smaller context for faster processing  
ONLYJOBS_N_GPU_LAYERS=22                    # optimal for M-series Macs

# Performance and reliability settings
ONLYJOBS_INFER_TIMEOUT_MS=15000             # timeout for LLM inference
ONLYJOBS_EARLY_STOP_JSON=1                  # enable streaming early-stop on complete JSON (30-60% latency reduction)
ONLYJOBS_INFER_MAX_CHARS=5000               # truncate long email bodies
ONLYJOBS_CACHE_TTL_HOURS=168                # 7 days cache TTL
ONLYJOBS_ENABLE_PREFILTER=1                 # 1=enable prefilter, 0=disable
ONLYJOBS_PREFILTER_REGEX=(application|applied|interview|assessment|recruit|recruiting|talent|offer|candidate|position|role|job|opening|hiring)

# Optional (Apple Silicon users can export LLAMA_METAL=1 in shell)
# ONLYJOBS_N_GPU_LAYERS=10

# (Optional) electron/local DB override
# ONLYJOBS_DB_PATH=

# Copy this file to .env and add your actual credentials